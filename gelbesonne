            print(f'scraping tweets with keyword: "{keyword}" ...')
            try:
                os.system(
                    f'snscrape twitter-{keyword_user_search_param} "{keyword} since:{since} until:{until} lang:{lang}" > {output_path}')
            except Exception as err:
                print(f"SNSCRAPE ERROR: {err}")



import snscrape.modules.twitter.

for tweet in snscrape.modules.twitter.TwitterProfileScraper('username').get_items():
	# Do something with the tweet object, e.g.
	print(tweet.url)

import re

text = "@RayFranco is answering to @jjconti, this is a real '@username83' but this is an@email.com, and this is a @probablyfaketwitterusername";

result = re.findall("(^|[^@\w])@(\w{1,15})", text)

print(result);

xxxxxxxxxxxxxxxxxxxx


import re
import pandas as pd

trump = pd.read_csv('https://drive.google.com/uc?export=download&id=1xRKHaP-QwACMydlDnyFPEaFdtskJuBa6')
trump.text = trump.apply(lambda row: re.sub(r"http\S+", "", row.text).lower(), 1)
trump.text = trump.apply(lambda row: " ".join(filter(lambda x:x[0]!="@", row.text.split())), 1)
trump.text = trump.apply(lambda row: " ".join(re.sub("[^a-zA-Z]+", " ", row.text).split()), 1)
trump = trump.loc[(trump.isRetweet == "f") & (trump.text != ""), :]
timestamps = trump.date.to_list()
tweets = trump.text.to_list()

https://pypi.org/project/keybert/

https://github.com/prachiprakash26/Keyword_Extractor_Python

https://gist.github.com/mahmoud/237eb20108b5805aed5f


xxxxxxxxxxxxxxxxxxxxxx


from transformers import pipeline
ner = pipeline('ner', model='xlm-roberta-large-finetuned-conll03-german')
ner('Ich bin Luisa aus Berlin.')




##########
import requests

from bs4 import BeautifulSoup

def extract_telegram(url):
  page = requests.get(url)
  soup = BeautifulSoup(page.content, 'html.parser')

  numbers = soup.find('div', class_='tgme_page_extra').contents[0]
  
  if "members" in numbers:
    n_all = int(numbers.split(",")[0].replace(" members", "").replace(" ", ""))
    n_online = int(numbers.split(",")[1].replace(" online", "").replace(" ", ""))
  elif "subscribers" in numbers:
   n_all = int(numbers.replace(" subscribers", "").replace(" ", ""))
   n_online = - 1

  else:
    n_all = -1
    n_online = -1
  return(n_all, n_online)

list_urls = ['https://t.me/querdenken', 'https://t.me/querdenken089']
for url in list_urls:
  
  n_all, n_online = extract_telegram(url)
  print(n_all)
  print(n_online)
